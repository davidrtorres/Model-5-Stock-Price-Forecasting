{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "The goal of this notebook is to provide analysis and insights that can be obtained from historical stock prices and their plots.  I obtained the stock historical data by using the Pandas library DataReader.  The library provide price and volumne information regarding a stock. I will use mainly the Adjusted Closing Price. <br> \n",
    "In addition, I will examine how Long Short Term Memory (LSTM )alogorithms and SARIMA models can be used based on the Adjusted Closing Price of stock to forecast the next day price of a stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "#from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from textblob import TextBlob \n",
    "from wordcloud import WordCloud \n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stock Price Trend Analysis for Adjusted Closing Price**\n",
    "The closing price of a stock is the price of that stock at the close of the trading day. The adjusted closing price uses the closing price as a starting point, but it also takes into account factors such as dividends, stock splits and new stock offerings to determine a value. The adjusted closing price represents a more accurate reflection of a stock's value, since distributions and new offerings can alter the closing price.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Single Stock Data and Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-2-e175a5961b54>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-e175a5961b54>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def single_stock_data(symbol, data_source,cols = 'Adj Close',start,end):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def single_stock_data(symbol, data_source,start,end):\n",
    "    df = web.DataReader(symbol,data_source, start, end) \n",
    "    #print('Dataset consisits of {} and {}'.format(df[0].shape,df[1].shape))\n",
    "    df_shape = df.shape\n",
    "    print('Dataframe consists of {} rows and {} columns'.format(df_shape[0],df_shape[1]))\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    #plot = go.Scatter(x=df.index, y=df['Adj Close'])\n",
    "    plt.plot(df['Adj Close'])\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multiple Stock Data and Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pfizer(PFE)   $51.75 billion.\n",
    "Roche(RO)    $50 billion.\n",
    "Novartis(NOVN) $47.45 billion.\n",
    "Merck(MRK)    $46.84 billion.\n",
    "GlaxoSmithKline(GSK) $43.54 billion.\n",
    "Johnson & Johnson(JNJ) $42.1 billion.\n",
    "\n",
    "Moderna (MRNA)\n",
    "Novavax (NVAX)\n",
    "\"\"\"\n",
    "def get_data_plot(ticker=None, start=None, end=None, plot=True, stock_value=None):\n",
    "    \n",
    "    try:\n",
    "        #stock = pdr.get_data_yahoo(ticker,start,end)\n",
    "        data = {}\n",
    "        for stock in ticker:\n",
    "            data = web.DataReader(stock,'yahoo',start,end)[stock_value]\n",
    "        df_1 = pd.DataFrame(data)#.reset_index()\n",
    "        if plot==True:\n",
    "            df_1.plot(figsize=(12,8))\n",
    "            plt.title(\"Stock Adjusted Price Historical Data\")\n",
    "            plt.xlabel('Dates')\n",
    "            plt.ylabel('Stock Prices')\n",
    "            plt.legend(bbox_to_anchor=(1.05,1),loc='upper left') \n",
    "#             plt.figure(figsize=(12,12))\n",
    "#             plt.plot(df_1)\n",
    "#             plt.title(\"Stock Adjusted Price Historical Data\")\n",
    "#             plt.xlabel('Dates')\n",
    "#             plt.ylabel('Stock Prices')\n",
    "#             plt.legend(bbox_to_anchor=(1.05,1),loc='upper left') \n",
    "        \n",
    "        return df_1\n",
    "     \n",
    "    except Exception as e:\n",
    "        print(\"Error occured:\", e)\n",
    "        #data = 'Incorrect Symbol'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = get_data_plot(ticker=[['PFE','JNJ','NVAX','MRNA','AZN']], start='2019',end='2021',plot=True, stock_value='Adj Close')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will divide each of the rows in the DataFrame by the first row. This will enable comparison across stocks since all stock prices will be shown as a percentage difference over time. A value lower than 1 indicates that the stock price has declined compared to the base date (i.e. 2017–10–04). A value higher than 1 indicates that the price has gone up.<br>\n",
    "Since prices are shown as a percentage of the first data point, the graph is specially useful to compare price trends from different companies. For example, we can see that NVAX has experienced massive growth in the last few weeks while the other stock prices have been increasing steadily since 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plot(ticker, start=None, end=None, plot=True, stock_value=None):\n",
    "    \n",
    "    try:\n",
    "        #stock = pdr.get_data_yahoo(ticker,start,end)\n",
    "        data = {}\n",
    "        for stock in ticker:\n",
    "            data = web.DataReader(stock,'yahoo',start,end)[stock_value]\n",
    "        df_1 = pd.DataFrame(data)#.reset_index()\n",
    "        #divide all dataframe by first line of data to enable comparison\n",
    "        histprice = df_1/df_1.iloc[0]\n",
    "\n",
    "        if plot==True:\n",
    "            histprice.plot(figsize=(12,8))\n",
    "            plt.title(\"Stock Adjusted Price Historical Data\")\n",
    "            plt.xlabel('Dates')\n",
    "            plt.ylabel('Stock Prices')\n",
    "            plt.legend(bbox_to_anchor=(1.05,1),loc='upper left') \n",
    "        \n",
    "        return histprice\n",
    "     \n",
    "    except Exception as e:\n",
    "        print(\"Error occured:\", e)\n",
    "        #data = 'Incorrect Symbol'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = data_plot([['PFE','JNJ','NVAX','MRNA','AZN']], plot=True, start='2019',end='2021',stock_value='Adj Close')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2.to_csv('pharma_stocks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharma = pd.read_csv('pharma_stocks.csv')\n",
    "pharma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vol = get_data_plot(ticker=[['PFE','JNJ','NVAX','MRNA','AZN']], start='2020-11-01',end='2021',plot=True, stock_value='Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_vol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aapl = web.DataReader('MRNA','yahoo','2018','2021')\n",
    "data_aapl['Price Change'] = data_aapl['Adj Close'].diff()\n",
    "data_aapl.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Daily Price Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_data_plot(ticker, plot=True):\n",
    " \n",
    "    try:\n",
    "        #stock = pdr.get_data_yahoo(ticker,start,end)\n",
    "        data = {}\n",
    "        for stock in ticker:\n",
    "            data = web.DataReader(stock,'yahoo','2018','2021')['Adj Close']\n",
    "        df_1 = pd.DataFrame(data)#.reset_index()\n",
    "        if plot==True:\n",
    "            df_1_diff = df_1.diff()\n",
    "            df_1_diff.plot(figsize=(12,8))\n",
    "            plt.title(\"Historical Stock Price Change\")\n",
    "            #plt.set(title=f'Housing Prices by Year - {zip_df.index.freq}')\n",
    "            plt.xlabel('Dates')\n",
    "            plt.ylabel('Stock Prices USD ($)')\n",
    "            plt.legend(bbox_to_anchor=(1.05,1),loc='upper left') \n",
    "        \n",
    "        return df_1_diff\n",
    "     \n",
    "    except Exception as e:\n",
    "        print(\"Error occured:\", e)\n",
    "        #data = 'Incorrect Symbol'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data_plot([['PFE','JNJ','NVAX','MRNA','AZN']], plot=True)\n",
    "diff_data_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter/Sentiment Analysis\n",
    "Below are the twitter feeds regarding the pharmaceutical companies and corresponding sentiment analysis of the feeds.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/davidtorres/.secret/config_Mod_5.json') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticate = tweepy.OAuthHandler(json_data['consumer_key'],json_data['consumer_secret_key'])\n",
    "authenticate.set_access_token(json_data['access_token'], json_data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(authenticate, wait_on_rate_limit= True)\n",
    "#api = tweepy.API(authenticate, wait_on_rate_limit= True)\n",
    "#api = tweepy.API(authenticate, wait_on_rate_limit= True)\n",
    "posts = api.user_timeline(screen_name='@pfizer', count=5, lang='en', tweet_mode='extended')\n",
    "#tweets = api.user_timeline(screen_name='whoever', count=5, tweet_mode='extended')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(posts):\n",
    "    tweet_list = []\n",
    "    for twt in posts:\n",
    "        tweet_list.append(twt._json)\n",
    "    tweet_data = pd.DataFrame.from_records(tweet_list)#tweet_df = tweet_data[['created_at','full_text']]\n",
    "    tweet_df = tweet_data[['created_at','full_text']]\n",
    "    tweet_df['Date'] = pd.to_datetime(tweet_df['created_at'])\n",
    "    tweet_df['Date'] = pd.to_datetime(tweet_df['Date'], format='%Y:%m:%d').dt.date\n",
    "    tweet_df.set_index([\"Date\"], inplace = True) \n",
    "    tweet_df.drop('created_at',axis=1,inplace=True)\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = get_tweets(posts)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the text\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #r-tells python that expression is a raw tring, once we find substitute fo empty string\n",
    "  #get rid of any hashtag or number sign\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'RT[\\s]+','', text)  #retweets followed by 1 or more white spaces\n",
    "    #remove the hyper link\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','', text)      #may have 0 or 1 s character\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning hte text\n",
    "tweets_df['full_text'] = tweets_df['full_text'].apply(cleanTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_data = tweets_df.to_csv('tweets_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_stock = pd.read_csv('tweets_data.csv',parse_dates=True, index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = ' '.join([twts for twts in tweets_df['full_text']])\n",
    "wordCloud = WordCloud(width=700, height=500, random_state=21,max_font_size=110).generate(allWords)\n",
    "plt.imshow(wordCloud,interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get subjectivity (how subjective or opinated text is)and pularity (how postive or negative text is)\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 2 new columns\n",
    "tweets_df['Subjectivity'] = tweets_df['full_text'].apply(getSubjectivity)\n",
    "tweets_df['Polarity'] = tweets_df['full_text'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnalysis(score):\n",
    "    #function to calculate the negative, neutral and positve analysis\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polarity is the score and going to apply the  function\n",
    "tweets_df['Analysis'] = tweets_df['Polarity'].apply(getAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Social Media on Stock Prices\n",
    "Pfizer we can see that in November and December 2020 there was a significant jumpy in the price of the stock and volume of trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pfizer = single_stock_data('PFE',data_source='yahoo', start='2020-01-01',end='2021-1-11')\n",
    "data_pfizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Indicators for Quantative Trading\n",
    "1. Simple Moving Average\n",
    "2. Average True Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Moving Average\n",
    "Simple Moving Average is one of the most common technical indicators.  SMA calculates the average of prices over a given interval of time and is used to determine the trend of the stock.<br>\n",
    "The most commonly used moving averages are the 5-day, 10-day, 20-day, 50-day, and the 200-day moving averages.<br>\n",
    "SMA takes hte prcie of stock over a certain number of periods and averages the price together. This is useful when trying to identify trends. Sometimres we can identify these trend changes when the SMA closing price drops over.  What this means for a ninvestor is that the closing price differes greatly frm the simple moving averageso it may be time to buy or sell as stock.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sma = single_stock_data('TSLA', plot=True, start='2019',end='2021',stock_value='Adj Close')\n",
    "df_sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "program uses the 3 moving averages crossoever stategy to determine when to buy and sell stock. \n",
    "calculate 3 moving averages\n",
    "\"\"\"\n",
    "#short or fast exponential moving average\n",
    "shortEMA = df_sma['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "#calcualte middle/medium exponential moving average\n",
    "middleEMA = df_sma['Adj Close'].ewm(span=21, adjust=False).mean()\n",
    "#calculte long/slow exponential moving average\n",
    "longEMA= df_sma['Adj Close'].ewm(span=63, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize adj closing pprice and exponential moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "concerned w/crossing of exponential averages\n",
    "this strategy tells us when to buy and when to sell the stock\n",
    "\"\"\"\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "df_sma.plot(template='plotly_dark')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_sma['Adj Close'],label='Adj Close',color='blue')\n",
    "plt.plot(shortEMA, label='Short/Fast',color='red')\n",
    "plt.plot(middleEMA,label='Middle',color='orange')\n",
    "plt.plot(longEMA,label='Long/slow',color='green')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\"\n",
    "df_sma.plot(template='plotly_dark')\n",
    "# fig = px.line(df_sma, x=df_sma.index, y='Adj Close')\n",
    "# fig = px.line(shortEMA, x=shortEMA.index, y='Adj Close')\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(df_sma, x=df_sma.index, y='Adj Close')\n",
    "# fig.update_layout(title='Productivity, Europe' , showlegend=False)\n",
    "\n",
    "\n",
    "# # Plotly figure 2\n",
    "# fig2 = go.Figure(fig.add_traces(\n",
    "#                  data=px.line(shortEMA, x=shortEMA.index, y='Adj Close')))\n",
    "# fig2.update_layout(title='Productivity, Europe and America', showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate when to buy and sell\n",
    "#add exponential moving averages to teh data set\n",
    "df_sma['Short'] = shortEMA\n",
    "df_sma['Middle'] = middleEMA\n",
    "df_sma['Long'] = longEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the function buy and sell stock\n",
    "def buy_sell_stock(data):\n",
    "    buy_list = []\n",
    "    sell_list = []\n",
    "    flag_long=False  #flags tell which portion of stratgy I'm in\n",
    "    flag_short=False\n",
    "    \n",
    "    for i in range(0,len(data)): #loop through and find all times that strategy applies\n",
    "        #when to buy stock\n",
    "        if data['Middle'][i] < data['Long'][i] and data['Short'][i] < data['Middle'][i] and flag_long == False and flag_short == False:\n",
    "            buy_list.append(data['Adj Close'][i])\n",
    "            sell_list.append(np.nan)\n",
    "            flag_short = True\n",
    "        #when to sell stock\n",
    "        elif flag_short == True and data['Short'][i] > data['Middle'][i]:\n",
    "            sell_list.append(data['Adj Close'][i])\n",
    "            buy_list.append(np.nan)\n",
    "            flag_short = False  \n",
    "                                 \n",
    "        elif data['Middle'][i] > data['Long'][i] and data['Short'][i] > data['Middle'][i] and flag_long == False and flag_short == False:\n",
    "            buy_list.append(data['Adj Close'][i])\n",
    "            sell_list.append(np.nan)\n",
    "            flag_long = True\n",
    "        #when to sell stock\n",
    "        elif flag_long == True and data['Short'][i] < data['Middle'][i]:\n",
    "            sell_list.append(data['Adj Close'][i])\n",
    "            buy_list.append(np.nan)\n",
    "            flag_long = False  \n",
    "        else:\n",
    "            buy_list.append(np.nan) \n",
    "            sell_list.append(np.nan) \n",
    "    return (buy_list,sell_list)                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add buy and sell signals to dataset\n",
    "df_sma['Buy'] = buy_sell_stock(df_sma)[0]\n",
    "df_sma['Sell'] = buy_sell_stock(df_sma)[1] #return index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visaully show stock buy and sell signals\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Buy and Sell Chart')\n",
    "plt.plot(df_sma['Adj Close'],label='Adj Close',color='blue',alpha=0.35)\n",
    "plt.plot(shortEMA, label='Short/Fast',color='red',alpha=0.35)\n",
    "plt.plot(middleEMA,label='Middle',color='orange',alpha=0.35)\n",
    "plt.plot(longEMA,label='Long/slow',color='green')\n",
    "plt.scatter(df_sma.index,df_sma['Buy'],color='green',marker='^',alpha=1) #show momentum stock going up\n",
    "plt.scatter(df_sma.index,df_sma['Sell'],color='red',marker='v',alpha=1) #show momentum stock going up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Forecasting**\n",
    "### Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol, data_source,start,end):\n",
    "    df = web.DataReader(symbol,data_source, start, end) \n",
    "    #print('Dataset consisits of {} and {}'.format(df[0].shape,df[1].shape))\n",
    "    df_shape = df.shape\n",
    "    print('Dataframe consists of {} rows and {} columns'.format(df_shape[0],df_shape[1]))\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(df['Adj Close'])\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data = get_data('MRNA',data_source='yahoo', start='2019-01-01',end='2021-1-11')\n",
    "the_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = the_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change in price for day\n",
    "#radio button or drop down\n",
    "the_data.diff()['Adj Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df['Prct_Change'] = the_data.diff().dropna()['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/apple_2012_1_1-2019_12_17.csv', parse_dates=True, index_col=[0])\n",
    "\n",
    "#Get the stock quote \n",
    "#df = web.DataReader('TGT', data_source='yahoo', start='2016-01-01', end='2021-1-11') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.diff().dropna() #zip_df[11226].diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df,percentage):\n",
    "    training_data_len = int(np.round(len(df) * percentage))\n",
    "    dataset = pd.DataFrame(df)\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    return training_data_len, dataset, scaler, scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data_len, dataset, scaler, scaled_data = preprocessing(df['Close'], percentage=.8)\n",
    "training_data_len, dataset, scaler, scaled_data = preprocessing(the_data['Adj Close'], percentage=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets(training_data_len):\n",
    "    #create training data set\n",
    "    train_data = scaled_data[0:training_data_len,:]\n",
    "    test_data = scaled_data[training_data_len -60:,:] #to 2003 which is end of dataset\n",
    "    #split data into X_train and y_train data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    #create dataset X_test and y_test data sets\n",
    "    X_test = []\n",
    "    y_test = []    #dataset.iloc[training_data_len:, :]\n",
    "\n",
    "\n",
    "    for i in range(60, len(train_data)):\n",
    "        X_train.append(train_data[i-60:i])\n",
    "        y_train.append(train_data[i,0]) #will contain 61st value which will be at position 60\n",
    "\n",
    "    for i in range(60, len(test_data)):\n",
    "        X_test.append(test_data[i-60:i,0]) \n",
    "        y_test.append(test_data[i,0])\n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)  \n",
    "    X_test = np.array(X_test) #added\n",
    "    X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1)) #added\n",
    "    y_test = np.array(y_test)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = create_sets(training_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "def create_model(X_train, y_train):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units = 25))\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks=[early_stop]\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit(X_train,y_train, epochs=10,batch_size=32,callbacks=[early_stop])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    model.save('model_parameters')\n",
    "    model_params = keras.models.load_model('model_parameters')\n",
    "    model_params.summary()\n",
    "\n",
    "    return model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_params = save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, X_test, y_test,training_data_len):\n",
    "    predictions = model.predict(X_test)\n",
    "    prediction_unscaled = scaler.inverse_transform(predictions) #unscaling the values\n",
    "    \n",
    "    y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1,1)) #unscaling the values\n",
    "    \n",
    "    #this is in dollars\n",
    "    rmse_predictions = np.sqrt(np.mean(prediction_unscaled -y_test_unscaled)**2)\n",
    "    rmse_predictions\n",
    "    \n",
    "    predictions = pd.DataFrame(prediction_unscaled, columns=['Predictions'])\n",
    "    \n",
    "    train = dataset[:training_data_len]\n",
    "    valid = dataset[training_data_len:] #data from index training_data_len to \n",
    "    \n",
    "    valid.reset_index(inplace=True)\n",
    "    valid['Prediction'] = predictions['Predictions']\n",
    "    valid1 = valid.set_index('Date')\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Model')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Close Price USD ($)')\n",
    "    plt.plot(train['Adj Close'])\n",
    "    #plt.plot(valid[['Close','Predictions']])\n",
    "    plt.plot(valid1['Adj Close'])\n",
    "    plt.plot(valid1['Prediction'])\n",
    "    # #valid[['Close','Predictions']].plot()\n",
    "    plt.legend(['Train','Valid','Predictions'],loc='lower right')\n",
    "    return rmse_predictions, valid1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(model, X_test,y_test, training_data_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "blue-data model was trainined on \n",
    "orange-actual closing stock price for rest of days\n",
    "green-what model predcited values to be\n",
    "\n",
    "predict closing price fo TGT stock for 2021-1-11  199.10\n",
    "\n",
    "get the quote\n",
    "\"\"\"\n",
    "def get_quote(new_df):\n",
    "    #get last 60days closing values and convert datframe to an array\n",
    "    last_60_days = new_df[-60:].values #converts to array\n",
    "    #scale data\n",
    "    last_60_days_scaled = scaler.transform(last_60_days)\n",
    "    #create empty list\n",
    "    x_test = []\n",
    "    #append last 60 days to x_test\n",
    "    x_test.append(last_60_days_scaled)\n",
    "    #conert x_test to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "    # #reshape the data\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "    #get the predicted scaled price\n",
    "    pred_price = model.predict(x_test)\n",
    "    #undo the scaling \n",
    "    pred_price = scaler.inverse_transform(pred_price) \n",
    "    #what model thinks predicted price will be for 12/18/2019\n",
    "    #the actual prcie was $69.94\n",
    "    #DAL: 58.58, 2021-1-11 40.19\n",
    "    return pred_price                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_quote(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the_data = get_data('AMZN',data_source='yahoo', start='2016-01-01',end='2021-1-11')\n",
    "# the_data\n",
    "# df_1 = get_data_plot(['AZN'], plot=True, start='2019',end='2021',stock_value='Adj Close')\n",
    "# df_1\n",
    "the_data_1 = get_data('TGT',data_source='yahoo', start='2019-01-01',end='2021-1-11')\n",
    "the_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_len, dataset, scaler, scaled_data = preprocessing(the_data_1['Adj Close'], percentage=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = create_sets(training_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train,y_train, epochs=50,batch_size=32,callbacks=[early_stop])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(model_params, X_test,y_test, training_data_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_quote(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA MODEL\n",
    "A time series is a sequence where we record a metric over regular intervals.  Forecasting is the future value that this sequence will take.<br>\n",
    "An ARIMA model is a forecasting algorithm that takes in previous past values to predict future values.  ARIMA models use past performance to predict future performance.  Based on its own lag and lag errors.  A SARIMA model is an ARIMA model with a seasonality component.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ARIMA is a forecasting model based on idea that information of past values may be indicative of future values.\n",
    "ARIMA explains a ts based on its own past values, basically its own lags and lagged forecast errors.\n",
    "\"\"\"\n",
    "# df_2 = web.DataReader('MRNA','yahoo','2019','2021')\n",
    "# df_2\n",
    "# df_1 = get_data_plot(ticker='AMZN', start='2019',end='2021',plot=True, stock_value='Adj Close')\n",
    "# df_1\n",
    "# data_sarima = get_data('MRNA',data_source='yahoo', start='2019-01-01',end='2021-1-11')\n",
    "# data_sarima\n",
    "the_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data = df_2.copy()\n",
    "df_data = pd.DataFrame(the_data_1['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data_len, dataset, scaler, scaled_data = preprocessing(df_data['Adj Close'], percentage=.8)\n",
    "n = int(len(df_data) * 0.8)\n",
    "train = df_data[:n]\n",
    "test = df_data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1265\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_data.index, df_data[\"Adj Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "import pmdarima as pm\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Need to find optimal parameters so you can fit ARIMA model.\n",
    "Forecasting using optimal parameters\n",
    "\"\"\"\n",
    "def arima_model(df):\n",
    "    \"\"\"\n",
    "    df- dataframe\n",
    "    function is a gridsearch to get optimal p,d,qs and lowest AIC for the model.\n",
    "    q-is moving average\n",
    "    \"\"\"\n",
    "    autoarima_model = auto_arima(df, start_p = 0, start_q = 0, #start_q = 0\n",
    "                              test='adf',             # use adftest to find optimal 'd'\n",
    "                              max_p = 3, max_q = 3,   # maximum p and q\n",
    "                              m = 12,                  #frequency of series \n",
    "                              d = None,               # let model determine 'd', was 1\n",
    "                              seasonal = True, \n",
    "                              start_P=0, D=1, trace = False, #start  #trace= True\n",
    "                              error_action ='ignore',   # we don't want to know if an order does not work \n",
    "                              suppress_warnings = True,  # we don't want convergence warnings \n",
    "                              stepwise = True)           # set to stepwise  \n",
    "    \n",
    "    #print('\\n')\n",
    "    #display(autoarima_model.summary())\n",
    "    \n",
    "    return autoarima_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit = arima_model(train['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_list = [['zipcode', 'pdq','seasonal_pdq','aic']] \n",
    "for col in df_data.columns:\n",
    "  zip_test_2 = arima_model(df_data[col])\n",
    "  arima_list.append([col,zip_test_2.order, zip_test_2.seasonal_order, zip_test_2.aic()])\n",
    "#result   \n",
    "output_df = pd.DataFrame(arima_list[1:],columns=arima_list[0]) \n",
    "output_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ARIMA(df, order=None, seasonal_order=None):\n",
    "    \"\"\"\n",
    "    forecasting statsmodel SARIMAX model\n",
    "    \"\"\"\n",
    "    ARIMA_MODEL = sm.tsa.statespace.SARIMAX(df, \n",
    "                                        order=order, \n",
    "                                        seasonal_order=seasonal_order, \n",
    "                                        enforce_stationarity=False, \n",
    "                                        enforce_invertibility=False)\n",
    "\n",
    "    # Fit the model and print results\n",
    "    output = ARIMA_MODEL.fit()\n",
    "\n",
    "    #display / no tables 1\n",
    "    display(output.summary())\n",
    "    \n",
    "    print('\\n')\n",
    "    print('MODEL DIAGNOSTICS')\n",
    "    \n",
    "    output.plot_diagnostics(figsize=(15, 18));\n",
    "    plt.show()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Adj Close'][[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Adj Close'][[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_zip = 'Adj Close'\n",
    "zip_params= output_df[output_df['zipcode']==current_zip]\n",
    "zip_params.pdq.values[0]\n",
    "zip_params.seasonal_pdq.values[0]\n",
    "\n",
    "output_sarima = fit_ARIMA(df_data[current_zip],order=zip_params.pdq.values[0], seasonal_order= zip_params.seasonal_pdq.values[0] )\n",
    "# Get dynamic predictions with confidence intervals as above \n",
    "\n",
    "pred = output_sarima.get_prediction(start=pd.to_datetime('2020-01-10'), dynamic=False)\n",
    "pred_conf = pred.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "ax = CO2['1990':].plot(label='observed')\n",
    "\n",
    "# Plot predicted values\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=0.9)\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "ax.fill_between(pred_conf.index,\n",
    "                pred_conf.iloc[:, 0],\n",
    "                pred_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "# Set axes labels\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('CO2 Levels')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# rcParams['figure.figsize'] = 15, 6\n",
    "# #plt.figure(figsize=(12,5))\n",
    "# # Plot observed values\n",
    "# ax = train['Adj Close']['2019':].plot(label='observed')#\n",
    "# test['Adj Close']['2019':].plot()#label='Test'\n",
    "# # Plot predicted values\n",
    "# pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=0.9)\n",
    "\n",
    "# # Plot the range for confidence intervals\n",
    "# ax.fill_between(pred_conf.index,\n",
    "#                 pred_conf.iloc[:, 0],\n",
    "#                 pred_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "# # Set axes labels\n",
    "# ax.set_xlabel('Date')\n",
    "# ax.set_ylabel('Sale Price')\n",
    "# plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the real and predicted values\n",
    "# forecasted_11238 = pred.predicted_mean\n",
    "# truth_1128 =test['Adj Close']['1996':]\n",
    "\n",
    "# # Compute the root mean square error\n",
    "# mse = ((forecasted_11238 - truth_1128) ** 2).mean()\n",
    "# print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\n",
    "# #np.sqrt(np.mean((predictions-targets)**2))\n",
    "# rmse = np.sqrt(np.mean((forecasted_11238 - truth_1128) ** 2))\n",
    "# print('The Root Mean Squared Error of our forecasts is {}'.format(round(rmse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_zip = 'Adj Close'\n",
    "zip_params = output_df[output_df['zipcode']==current_zip]\n",
    "zip_params.pdq.values[0]\n",
    "zip_params.seasonal_pdq.values[0]\n",
    "\n",
    "output_sarima = fit_ARIMA(df_data[current_zip],order=zip_params.pdq.values[0] ,seasonal_order= zip_params.seasonal_pdq.values[0] )\n",
    "# Get dynamic predictions with confidence intervals as above \n",
    "pred_dynamic = output_sarima.get_prediction(start=pd.to_datetime('2020-01-10'), dynamic=True,full_results=True)\n",
    "pred_dynamic_conf = pred_dynamic.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_vis(pred_dynamic,pred_dynamic_conf, y):\n",
    "  # Plot the dynamic forecast with confidence intervals.\n",
    "  plt.figure(figsize=(12,5))\n",
    "  # Plot observed values\n",
    "  ax = y.plot(label='Observed')\n",
    "\n",
    "  # Plot predicted values\n",
    "  pred_dynamic.predicted_mean.plot(ax=ax, label='Dynamic Forecast', alpha=0.9)\n",
    "\n",
    "  # Plot the range for confidence intervals\n",
    "  ax.fill_between(pred_dynamic_conf.index,\n",
    "                  pred_dynamic_conf.iloc[:, 0],\n",
    "                  pred_dynamic_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "  # Set axes labels\n",
    "  ax.set_xlabel('Date')\n",
    "  ax.set_ylabel('Sale Price')\n",
    "  plt.legend()\n",
    "\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_visual = prediction_vis(pred_dynamic,pred_dynamic_conf,train[current_zip])\n",
    "# prediction_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the real and predicted values\n",
    "forecast_11238 = pred_dynamic.predicted_mean\n",
    "truth_11238 = train[current_zip]#['1996':]\n",
    "\n",
    "# Compute the mean square error\n",
    "mse = ((forecast_11238 - truth_11238) ** 2).mean()\n",
    "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\n",
    "#np.sqrt(np.mean((predictions-targets)**2))\n",
    "rmse = np.sqrt(np.mean((forecast_11238 - truth_11238) ** 2))\n",
    "print('The Root Mean Squared Error of our forecasts is {}'.format(round(rmse, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
